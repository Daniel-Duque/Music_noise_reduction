{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(file_path):\n",
    "    audio_array, sample_rate= librosa.load(file_path)\n",
    "    spec = librosa.feature.melspectrogram(y=audio_array,\n",
    "                                    sr=sample_rate, \n",
    "                                        n_fft=2048, \n",
    "                                        hop_length=512, \n",
    "                                        win_length=None, \n",
    "                                        window='hann', \n",
    "                                        center=True, \n",
    "                                        pad_mode='reflect', \n",
    "                                        power=2.0,\n",
    "                                    n_mels=128)\n",
    "    log_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    return spec,sample_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando con un archivo limpio y uno con overlay de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file=r'wavs\\clean\\clnsp0.wav'\n",
    "noise_file=r'wavs\\noisy\\output1.wav'\n",
    "test_clean_spec,test_clean_sr =create_spectrogram(clean_file)\n",
    "test_noisy_spec,test_noisy_sr=create_spectrogram(noise_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 475), (128, 475))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_spec.shape,test_noisy_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test_clean_spec.shape[1]/128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 95)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hsplit(test_clean_spec,5)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_noisy_sr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador de archivos en masa usando batcheador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "def create_spec_from_dir(dir_path,top_x=200):\n",
    "    #dir_path directorio o folder donde estan los wavs\n",
    "    # top_x opcional cuantos archivos maximo desea usar, dejar vacio para usarlos todos\n",
    "    dir = os.listdir(dir_path)\n",
    "    spec_list=[]\n",
    "    s_rates=[]\n",
    "    for i, file in enumerate(dir):\n",
    "        try:\n",
    "            if i<=top_x:\n",
    "                input_file = os.path.join(dir_path, file)\n",
    "                ms,sr=create_spectrogram(input_file)\n",
    "                num_batches=ceil(ms.shape[1]/128) if ms.shape[1]>128 else 1\n",
    "                ms=np.resize(ms,(ms.shape[0],128*num_batches))\n",
    "                batches=np.hsplit(ms,num_batches)\n",
    "                for batch in batches:\n",
    "                    spec_list.append(batch)\n",
    "                    s_rates.append(sr)\n",
    "        except:\n",
    "            print(file,\" file skipped\")\n",
    "    \n",
    "    return spec_list,s_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_specs,clean_s_rates=create_spec_from_dir(r'wavs\\clean',24175)\n",
    "noisy_specs,noisy_s_rates=create_spec_from_dir(r'wavs\\noisy',24175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37537, 37533)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_specs),len(noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_specs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 22050)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(clean_s_rates),max(clean_s_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 22050)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(noisy_s_rates),max(noisy_s_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_specs(clean_specs,noisy_specs):\n",
    "    \n",
    "    #getting max lenght of all audios\n",
    "    max_y=0\n",
    "    \n",
    "    for i,j in zip(clean_specs,noisy_specs):\n",
    "        if i.shape[1]>max_y: max_y=i.shape[1]\n",
    "        if j.shape[1]>max_y: max_y=j.shape[1]\n",
    "    print(max_y)\n",
    "    # reshapping all spectrogram\n",
    "\n",
    "    for index,s in enumerate(clean_specs):\n",
    "        try:\n",
    "            clean_specs[index]=np.resize(s,(s.shape[0],max_y))\n",
    "        except Exception as e:\n",
    "            print(f\"skipping clean {index} {e}\")\n",
    "    \n",
    "    clean_specs=np.array(clean_specs)\n",
    "    clean_specs=clean_specs.reshape(-1,s.shape[0],max_y,1)\n",
    "\n",
    "    for index,s in enumerate(noisy_specs):\n",
    "        try:\n",
    "            noisy_specs[index]=np.resize(s,(s.shape[0],max_y))\n",
    "        except Exception as e:\n",
    "            print(f\"skipping noise {index} {e}\")\n",
    "            \n",
    "    noisy_specs=np.array(noisy_specs)\n",
    "    noisy_specs=noisy_specs.reshape(-1,s.shape[0],max_y,1)\n",
    "\n",
    "    return clean_specs,noisy_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "s_clean_specs,s_noisy_specs=standardize_specs(clean_specs,noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s_clean_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=min(s_clean_specs.shape[0],s_noisy_specs.shape[0])\n",
    "s_clean_specs=s_clean_specs[:samples]\n",
    "s_noisy_specs=s_noisy_specs[:samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(s_noisy_specs, s_clean_specs, 32)\n",
    "#test_gen = DataGenerator(X_test, y_test, 32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Dense,Flatten,Reshape,InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#import mlflow\n",
    "#import mlflow.tensorflow\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 0\n",
    "\n",
    "solo 2 capas densas y regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                1048640   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16384)             1064960   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,117,760\n",
      "Trainable params: 2,117,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 82.9181\n",
      "Epoch 2/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 78.6145\n",
      "Epoch 3/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 78.1446\n",
      "Epoch 4/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.9021\n",
      "Epoch 5/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.7246\n",
      "Epoch 6/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.5421\n",
      "Epoch 7/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.3241\n",
      "Epoch 8/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.0489\n",
      "Epoch 9/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.8713\n",
      "Epoch 10/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.6528\n",
      "Epoch 11/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.4831\n",
      "Epoch 12/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.2503\n",
      "Epoch 13/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.0405\n",
      "Epoch 14/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.9019\n",
      "Epoch 15/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.7556\n",
      "Epoch 16/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.6106\n",
      "Epoch 17/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.4630\n",
      "Epoch 18/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.3354\n",
      "Epoch 19/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.2187\n",
      "Epoch 20/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.0703\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder0=models.Sequential()\n",
    "auto_encoder0.add(layers.Input(shape=img_shape))\n",
    "auto_encoder0.add(layers.Flatten())\n",
    "auto_encoder0.add(layers.Dense(64))\n",
    "auto_encoder0.add(layers.Dropout(drop_out))\n",
    "auto_encoder0.add(layers.Dense(64))\n",
    "auto_encoder0.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder0.add(layers.Reshape(img_shape))\n",
    "auto_encoder0.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder0.summary()\n",
    "\n",
    "history0 = auto_encoder0.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 1\n",
    "\n",
    "capas más complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               2097280   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,539,648\n",
      "Trainable params: 4,539,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 86.1028\n",
      "Epoch 2/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 79.1045\n",
      "Epoch 3/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 78.4176\n",
      "Epoch 4/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 78.0311\n",
      "Epoch 5/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.8939\n",
      "Epoch 6/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.7461\n",
      "Epoch 7/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.5905\n",
      "Epoch 8/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.5223\n",
      "Epoch 9/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.2550\n",
      "Epoch 10/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.1550\n",
      "Epoch 11/20\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 77.0158\n",
      "Epoch 12/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.8509\n",
      "Epoch 13/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.6808\n",
      "Epoch 14/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.5008\n",
      "Epoch 15/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.3533\n",
      "Epoch 16/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.2468\n",
      "Epoch 17/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.0532\n",
      "Epoch 18/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 75.8877\n",
      "Epoch 19/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 75.7640\n",
      "Epoch 20/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 75.5955\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder=models.Sequential()\n",
    "auto_encoder.add(layers.Input(shape=img_shape))\n",
    "auto_encoder.add(layers.Flatten())\n",
    "auto_encoder.add(layers.Dense(128))\n",
    "auto_encoder.add(layers.Dropout(drop_out))\n",
    "auto_encoder.add(layers.Dense(256))\n",
    "auto_encoder.add(layers.Dropout(drop_out))\n",
    "auto_encoder.add(layers.Dense(512))\n",
    "auto_encoder.add(layers.Dropout(drop_out))\n",
    "auto_encoder.add(layers.Dense(256))\n",
    "auto_encoder.add(layers.Dense(128))\n",
    "auto_encoder.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder.add(layers.Reshape(img_shape))\n",
    "\n",
    "\n",
    "auto_encoder.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder.summary()\n",
    "\n",
    "history1 = auto_encoder.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                1048640   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16384)             1064960   \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               2097280   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,345,088\n",
      "Trainable params: 6,345,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "356/356 [==============================] - 2s 4ms/step - loss: 80.6228\n",
      "Epoch 2/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 78.1428\n",
      "Epoch 3/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 78.0070\n",
      "Epoch 4/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.9280\n",
      "Epoch 5/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.6898\n",
      "Epoch 6/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.6544\n",
      "Epoch 7/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.5551\n",
      "Epoch 8/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.4454\n",
      "Epoch 9/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.3780\n",
      "Epoch 10/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.3480\n",
      "Epoch 11/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.2683\n",
      "Epoch 12/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.2343\n",
      "Epoch 13/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.1371\n",
      "Epoch 14/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.0936\n",
      "Epoch 15/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 77.0297\n",
      "Epoch 16/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.9241\n",
      "Epoch 17/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.8740\n",
      "Epoch 18/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.7510\n",
      "Epoch 19/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.7091\n",
      "Epoch 20/20\n",
      "356/356 [==============================] - 1s 4ms/step - loss: 76.5915\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder2=models.Sequential()\n",
    "auto_encoder2.add(layers.Input(shape=img_shape))\n",
    "auto_encoder2.add(layers.Flatten())\n",
    "auto_encoder2.add(layers.Dense(64))\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Dense(64))\n",
    "auto_encoder2.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder2.add(layers.Reshape(img_shape))\n",
    "auto_encoder2.add(layers.Flatten())\n",
    "auto_encoder2.add(layers.Dense(128))\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Dense(128))\n",
    "auto_encoder2.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder2.add(layers.Reshape(img_shape))\n",
    "auto_encoder2.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder2.summary()\n",
    "\n",
    "history2 = auto_encoder2.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                524320    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 16384)             540672    \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,066,048\n",
      "Trainable params: 1,066,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 79.9132\n",
      "Epoch 2/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 78.2325\n",
      "Epoch 3/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.9861\n",
      "Epoch 4/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.8450\n",
      "Epoch 5/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.6993\n",
      "Epoch 6/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.5614\n",
      "Epoch 7/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.4030\n",
      "Epoch 8/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.2589\n",
      "Epoch 9/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.1250\n",
      "Epoch 10/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 77.0057\n",
      "Epoch 11/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.9149\n",
      "Epoch 12/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.7006\n",
      "Epoch 13/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.5992\n",
      "Epoch 14/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.4779\n",
      "Epoch 15/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.3892\n",
      "Epoch 16/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.3015\n",
      "Epoch 17/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.2054\n",
      "Epoch 18/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.1105\n",
      "Epoch 19/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 76.0338\n",
      "Epoch 20/20\n",
      "356/356 [==============================] - 1s 3ms/step - loss: 75.9739\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder3=models.Sequential()\n",
    "auto_encoder3.add(layers.Input(shape=img_shape))\n",
    "auto_encoder3.add(layers.Flatten())\n",
    "auto_encoder3.add(layers.Dense(32))\n",
    "auto_encoder3.add(layers.Dropout(drop_out))\n",
    "auto_encoder3.add(layers.Dense(32))\n",
    "auto_encoder3.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder3.add(layers.Reshape(img_shape))\n",
    "auto_encoder3.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder3.summary()\n",
    "\n",
    "history3 = auto_encoder3.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    batch_size=32\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape_cnn=(s_clean_specs.shape[1],s_clean_specs.shape[2],1)\n",
    "img_shape_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89856"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod((128, 702))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11377, 128, 128, 1), (11377, 128, 128, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_clean_specs.shape,s_noisy_specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 128, 128, 3)       30        \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 49152)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_20120\\2784571528.py\", line 11, in <module>\n      history_cnn0 = cnn_auto_encoder0.fit(train_gen,\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\losses.py\", line 1327, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nrequired broadcastable shapes\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_113616]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m cnn_auto_encoder0\u001b[39m.\u001b[39msummary()\n\u001b[0;32m     10\u001b[0m cnn_auto_encoder0\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madamax\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m history_cnn0 \u001b[39m=\u001b[39m cnn_auto_encoder0\u001b[39m.\u001b[39;49mfit(train_gen,\n\u001b[0;32m     12\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     13\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m\n\u001b[0;32m     14\u001b[0m                     )\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_20120\\2784571528.py\", line 11, in <module>\n      history_cnn0 = cnn_auto_encoder0.fit(train_gen,\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\keras\\losses.py\", line 1327, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nrequired broadcastable shapes\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_113616]"
     ]
    }
   ],
   "source": [
    "img_shape_cnn=(s_clean_specs.shape[1],s_clean_specs.shape[2],1)\n",
    "\n",
    "cnn_auto_encoder0=models.Sequential()\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 3, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu', input_shape = (128,128,1)))\n",
    "\n",
    "cnn_auto_encoder0.add(layers.Flatten())\n",
    "\n",
    "cnn_auto_encoder0.summary()\n",
    "cnn_auto_encoder0.compile(optimizer='adamax', loss='mse')\n",
    "history_cnn0 = cnn_auto_encoder0.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    batch_size=8\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 128, 702, 32)      832       \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 128, 702, 32)      25632     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 64, 351, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64, 351, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64, 351, 32)       0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 718848)            0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 512)               368050688 \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 89856)             5840640   \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 128, 702, 1)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 373,950,752\n",
      "Trainable params: 373,950,688\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2],1)\n",
    "auto_encoder2=models.Sequential()\n",
    "auto_encoder2.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                activation ='relu', input_shape = img_shape))\n",
    "auto_encoder2.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "auto_encoder2.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "auto_encoder2.add(layers.BatchNormalization())\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Flatten())\n",
    "auto_encoder2.add(layers.Dense(512, activation = \"relu\"))\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Dense(64, activation = \"softmax\"))\n",
    "auto_encoder2.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder2.add(layers.Reshape(img_shape))\n",
    "\n",
    "auto_encoder2.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 82.3141\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 82.2238\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 82.1419\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 82.0619\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 25s 78ms/step - loss: 81.9885\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.9242\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.8656\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.8094\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.7610\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.7171\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.6769\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.6403\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.6069\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.5766\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 81.5484\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 81.5227\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 81.4990\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 81.4774\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 81.4560\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 24s 78ms/step - loss: 81.4370\n"
     ]
    }
   ],
   "source": [
    "#history2 = auto_encoder2.fit(x=s_noisy_specs, y=s_clean_specs, epochs=100)\n",
    "history2 = auto_encoder2.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "preds=auto_encoder.predict(s_noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 128, 702)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 702)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.88221908e-04, 2.46463984e-04, 2.61851761e-04, ...,\n",
       "        2.57317000e-03, 8.99837411e-04, 2.44650152e-03],\n",
       "       [1.21181156e-03, 9.17276135e-04, 9.90588916e-04, ...,\n",
       "        5.54336328e-03, 2.85331719e-02, 2.60114968e-01],\n",
       "       [1.14793324e+00, 1.52739763e+00, 1.82428646e+00, ...,\n",
       "        2.50480145e-01, 8.19973946e-02, 4.72248858e-03],\n",
       "       ...,\n",
       "       [9.29996677e-05, 9.84362341e-05, 1.06841406e-04, ...,\n",
       "        2.54283252e-04, 6.28159833e-05, 1.36140082e-03],\n",
       "       [2.84687756e-03, 9.32404399e-03, 1.19536798e-02, ...,\n",
       "        1.18909981e-02, 1.26775932e-02, 8.28386191e-03],\n",
       "       [6.48943149e-03, 3.44618829e-03, 1.06449577e-03, ...,\n",
       "        2.61219740e-02, 3.30388226e-04, 1.67555991e-04]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_specs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_log=librosa.db_to_power(preds[0])\n",
    "# step3 converting mel-spectrogrma back to wav file\n",
    "res = librosa.feature.inverse.mel_to_audio(reversed_log, \n",
    "                                           sr=noisy_s_rates[0], \n",
    "                                           n_fft=2048, \n",
    "                                           hop_length=512, \n",
    "                                           win_length=None, \n",
    "                                           window='hann', \n",
    "                                           center=True, \n",
    "                                           pad_mode='reflect', \n",
    "                                           power=2.0, \n",
    "                                           n_iter=32)\n",
    "\n",
    "import soundfile as sf\n",
    "sf.write(\"test2.wav\", res, noisy_s_rates[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertidor de espectrograma a audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 - converting a wav file to numpy array and then converting that to mel-spectrogram\n",
    "scale_file=r'wavs\\clean\\clnsp0.wav'\n",
    "my_audio_as_np_array, my_sample_rate= librosa.load(scale_file)\n",
    "\n",
    "# step2 - converting audio np array to spectrogram\n",
    "spec = librosa.feature.melspectrogram(y=my_audio_as_np_array,\n",
    "                                        sr=my_sample_rate, \n",
    "                                            n_fft=2048, \n",
    "                                            hop_length=512, \n",
    "                                            win_length=None, \n",
    "                                            window='hann', \n",
    "                                            center=True, \n",
    "                                            pad_mode='reflect', \n",
    "                                            power=2.0,\n",
    "                                     n_mels=128)\n",
    "log_spec = librosa.power_to_db(spec)\n",
    "reversed_log=librosa.db_to_power(log_spec)\n",
    "# step3 converting mel-spectrogrma back to wav file\n",
    "res = librosa.feature.inverse.mel_to_audio(reversed_log, \n",
    "                                           sr=my_sample_rate, \n",
    "                                           n_fft=2048, \n",
    "                                           hop_length=512, \n",
    "                                           win_length=None, \n",
    "                                           window='hann', \n",
    "                                           center=True, \n",
    "                                           pad_mode='reflect', \n",
    "                                           power=2.0, \n",
    "                                           n_iter=32)\n",
    "\n",
    "# step4 - save it as a wav file\n",
    "import soundfile as sf\n",
    "sf.write(\"test1.wav\", res, my_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('scale.wav', scale, sr, format='ogg', subtype='vorbis')\n",
    "sf.write('audio.wav', audio, sr, format='ogg', subtype='vorbis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
