{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(file_path):\n",
    "    audio_array, sample_rate= librosa.load(file_path)\n",
    "    spec = librosa.feature.melspectrogram(y=audio_array,\n",
    "                                    sr=sample_rate, \n",
    "                                        n_fft=2048, \n",
    "                                        hop_length=512, \n",
    "                                        win_length=None, \n",
    "                                        window='hann', \n",
    "                                        center=True, \n",
    "                                        pad_mode='reflect', \n",
    "                                        power=1.0,\n",
    "                                    n_mels=128)\n",
    "    log_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    return spec,sample_rate\n",
    " \n",
    "\n",
    "def reverse_spectrogram(log_spec,sample_rate, output_path):\n",
    "    #reversed_log=librosa.db_to_power(log_spec)\n",
    "    # step3 converting mel-spectrogrma back to wav file\n",
    "    res = librosa.feature.inverse.mel_to_audio(log_spec, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_fft=2048, \n",
    "                                        hop_length=512, \n",
    "                                        win_length=None, \n",
    "                                        window='hann', \n",
    "                                        center=True, \n",
    "                                        pad_mode='reflect', \n",
    "                                        power=1.0, \n",
    "                                        n_iter=32)\n",
    "\n",
    "    # step4 - save it as a wav file\n",
    "    import soundfile as sf\n",
    "    sf.write(output_path, res, sample_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando con un archivo limpio y uno con overlay de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file=r'wavs\\clean\\clnsp0.wav'\n",
    "noise_file=r'wavs\\noisy\\clnsp0.wav'\n",
    "test_clean_spec,test_clean_sr =create_spectrogram(clean_file)\n",
    "test_noisy_spec,test_noisy_sr=create_spectrogram(noise_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_clean_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 475), (128, 475))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_spec.shape,test_noisy_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 22050)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_sr,test_noisy_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devolviendo a .wav\n",
    "reverse_spectrogram(test_clean_spec,test_clean_sr,'test_clean_spec.wav')\n",
    "reverse_spectrogram(test_noisy_spec,test_noisy_sr,'test_noisy_spec.wav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador de archivos en masa usando batcheador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "def create_spec_from_dir(dir_path,top_x=200):\n",
    "    #dir_path directorio o folder donde estan los wavs\n",
    "    # top_x opcional cuantos archivos maximo desea usar, dejar vacio para usarlos todos\n",
    "    dir = os.listdir(dir_path)\n",
    "    spec_list=[]\n",
    "    s_rates=[]\n",
    "    for i, file in enumerate(dir):\n",
    "        try:\n",
    "            if i<=top_x:\n",
    "                input_file = os.path.join(dir_path, file)\n",
    "                ms,sr=create_spectrogram(input_file)\n",
    "                num_batches=ceil(ms.shape[1]/128) if ms.shape[1]>128 else 1\n",
    "                #print(ms.shape)\n",
    "                ms=np.resize(ms,(ms.shape[0],128*num_batches))\n",
    "                batches=np.hsplit(ms,num_batches)\n",
    "                for batch in batches:\n",
    "                    spec_list.append(batch)\n",
    "                    s_rates.append(sr)\n",
    "        except:\n",
    "            print(file,\" file skipped\")\n",
    "    \n",
    "    return spec_list,s_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_specs,clean_s_rates=create_spec_from_dir(r'wavs\\clean',24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_specs,noisy_s_rates=create_spec_from_dir(r'wavs\\noisy',24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37301, 37297)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_specs),len(noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_specs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 22050)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(clean_s_rates),max(clean_s_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, 22050)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(noisy_s_rates),max(noisy_s_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_specs(clean_specs,noisy_specs):\n",
    "    \n",
    "    #getting max lenght of all audios\n",
    "    max_y=0\n",
    "    \n",
    "    for i,j in zip(clean_specs,noisy_specs):\n",
    "        if i.shape[1]>max_y: max_y=i.shape[1]\n",
    "        if j.shape[1]>max_y: max_y=j.shape[1]\n",
    "    print(max_y)\n",
    "    # reshapping all spectrogram\n",
    "\n",
    "    for index,s in enumerate(clean_specs):\n",
    "        try:\n",
    "            clean_specs[index]=np.resize(s,(s.shape[0],max_y))\n",
    "        except Exception as e:\n",
    "            print(f\"skipping clean {index} {e}\")\n",
    "    \n",
    "    clean_specs=np.array(clean_specs)\n",
    "    clean_specs=clean_specs.reshape(-1,s.shape[0],max_y,1)\n",
    "\n",
    "    for index,s in enumerate(noisy_specs):\n",
    "        try:\n",
    "            noisy_specs[index]=np.resize(s,(s.shape[0],max_y))\n",
    "        except Exception as e:\n",
    "            print(f\"skipping noise {index} {e}\")\n",
    "            \n",
    "    noisy_specs=np.array(noisy_specs)\n",
    "    noisy_specs=noisy_specs.reshape(-1,s.shape[0],max_y,1)\n",
    "\n",
    "    return clean_specs,noisy_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "s_clean_specs,s_noisy_specs=standardize_specs(clean_specs,noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s_clean_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37301, 128, 128, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_clean_specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=min(s_clean_specs.shape[0],s_noisy_specs.shape[0])\n",
    "s_clean_specs=s_clean_specs[:samples]\n",
    "s_noisy_specs=s_noisy_specs[:samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(s_clean_specs, s_clean_specs, 32)\n",
    "#test_gen = DataGenerator(X_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 - converting a wav file to numpy array and then converting that to mel-spectrogram\n",
    "scale_file=r'wavs\\clean\\clnsp0.wav'\n",
    "my_audio_as_np_array, my_sample_rate= librosa.load(scale_file)\n",
    "\n",
    "# step2 - converting audio np array to spectrogram\n",
    "spec = librosa.feature.melspectrogram(y=my_audio_as_np_array,\n",
    "                                        sr=my_sample_rate, \n",
    "                                            n_fft=2048, \n",
    "                                            hop_length=512, \n",
    "                                            win_length=None, \n",
    "                                            window='hann', \n",
    "                                            center=True, \n",
    "                                            pad_mode='reflect', \n",
    "                                            power=2.0,\n",
    "                                     n_mels=128)\n",
    "log_spec = librosa.power_to_db(spec)\n",
    "reversed_log=librosa.db_to_power(log_spec)\n",
    "# step3 converting mel-spectrogrma back to wav file\n",
    "res = librosa.feature.inverse.mel_to_audio(reversed_log, \n",
    "                                           sr=my_sample_rate, \n",
    "                                           n_fft=2048, \n",
    "                                           hop_length=512, \n",
    "                                           win_length=None, \n",
    "                                           window='hann', \n",
    "                                           center=True, \n",
    "                                           pad_mode='reflect', \n",
    "                                           power=2.0, \n",
    "                                           n_iter=32)\n",
    "\n",
    "# step4 - save it as a wav file\n",
    "import soundfile as sf\n",
    "sf.write(\"test1.wav\", res, my_sample_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Dense,Flatten,Reshape,InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#import mlflow\n",
    "#import mlflow.tensorflow\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 0\n",
    "\n",
    "solo 2 capas densas y regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1048640   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16384)             1064960   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,117,760\n",
      "Trainable params: 2,117,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "1166/1166 [==============================] - 19s 12ms/step - loss: 0.0590\n",
      "Epoch 2/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0548\n",
      "Epoch 3/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0538\n",
      "Epoch 4/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0533\n",
      "Epoch 5/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0530\n",
      "Epoch 6/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0528\n",
      "Epoch 7/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0527\n",
      "Epoch 8/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0526\n",
      "Epoch 9/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0525\n",
      "Epoch 10/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0524\n",
      "Epoch 11/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0524\n",
      "Epoch 12/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0523\n",
      "Epoch 13/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0522\n",
      "Epoch 14/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0522\n",
      "Epoch 15/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0522\n",
      "Epoch 16/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0522\n",
      "Epoch 17/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0522\n",
      "Epoch 18/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0521\n",
      "Epoch 19/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0521\n",
      "Epoch 20/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0521\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder0=models.Sequential()\n",
    "auto_encoder0.add(layers.Input(shape=img_shape))\n",
    "auto_encoder0.add(layers.Flatten())\n",
    "auto_encoder0.add(layers.Dense(64))\n",
    "auto_encoder0.add(layers.Dropout(drop_out))\n",
    "auto_encoder0.add(layers.Dense(64))\n",
    "auto_encoder0.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder0.add(layers.Reshape(img_shape))\n",
    "auto_encoder0.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder0.summary()\n",
    "\n",
    "history0 = auto_encoder0.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds0=auto_encoder0.predict(s_noisy_specs)\n",
    "reverse_spectrogram(preds0[0],clean_s_rates[0],'test_auto_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_s_rates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 1\n",
    "\n",
    "capas más complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               2097280   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,539,648\n",
      "Trainable params: 4,539,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "1166/1166 [==============================] - 6s 4ms/step - loss: 0.0587\n",
      "Epoch 2/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0543\n",
      "Epoch 3/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0530\n",
      "Epoch 4/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0523\n",
      "Epoch 5/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0518\n",
      "Epoch 6/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0515\n",
      "Epoch 7/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0512\n",
      "Epoch 8/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0510\n",
      "Epoch 9/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0509\n",
      "Epoch 10/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0507\n",
      "Epoch 11/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0506\n",
      "Epoch 12/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0505\n",
      "Epoch 13/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0504\n",
      "Epoch 14/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0503\n",
      "Epoch 15/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0502\n",
      "Epoch 16/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0502\n",
      "Epoch 17/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0501\n",
      "Epoch 18/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0501\n",
      "Epoch 19/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0500\n",
      "Epoch 20/20\n",
      "1166/1166 [==============================] - 4s 4ms/step - loss: 0.0500\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder=models.Sequential()\n",
    "auto_encoder.add(layers.Input(shape=img_shape))\n",
    "auto_encoder.add(layers.Flatten())\n",
    "auto_encoder.add(layers.Dense(128))\n",
    "auto_encoder.add(layers.Dropout(drop_out))\n",
    "auto_encoder.add(layers.Dense(256))\n",
    "auto_encoder.add(layers.Dropout(drop_out))\n",
    "auto_encoder.add(layers.Dense(512))\n",
    "auto_encoder.add(layers.Dropout(drop_out))\n",
    "auto_encoder.add(layers.Dense(256))\n",
    "auto_encoder.add(layers.Dense(128))\n",
    "auto_encoder.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder.add(layers.Reshape(img_shape))\n",
    "\n",
    "\n",
    "auto_encoder.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder.summary()\n",
    "\n",
    "history1 = auto_encoder.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                1048640   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16384)             1064960   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               2097280   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               4194560   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16384)             4210688   \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,816,128\n",
      "Trainable params: 14,816,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "1166/1166 [==============================] - 21s 5ms/step - loss: 0.0622\n",
      "Epoch 2/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0591\n",
      "Epoch 3/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0578\n",
      "Epoch 4/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0570\n",
      "Epoch 5/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0565\n",
      "Epoch 6/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0561\n",
      "Epoch 7/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0558\n",
      "Epoch 8/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0556\n",
      "Epoch 9/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0555\n",
      "Epoch 10/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0554\n",
      "Epoch 11/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0554\n",
      "Epoch 12/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0553\n",
      "Epoch 13/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0552\n",
      "Epoch 14/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0552\n",
      "Epoch 15/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0552\n",
      "Epoch 16/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0551\n",
      "Epoch 17/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0551\n",
      "Epoch 18/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0551\n",
      "Epoch 19/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0551\n",
      "Epoch 20/20\n",
      "1166/1166 [==============================] - 5s 4ms/step - loss: 0.0551\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder2=models.Sequential()\n",
    "auto_encoder2.add(layers.Input(shape=img_shape))\n",
    "auto_encoder2.add(layers.Flatten())\n",
    "auto_encoder2.add(layers.Dense(64))\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Dense(64))\n",
    "auto_encoder2.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder2.add(layers.Reshape(img_shape))\n",
    "auto_encoder2.add(layers.Flatten())\n",
    "auto_encoder2.add(layers.Dense(128))\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Dense(128))\n",
    "auto_encoder2.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder2.add(layers.Reshape(img_shape))\n",
    "auto_encoder2.add(layers.Flatten())\n",
    "auto_encoder2.add(layers.Dense(256))\n",
    "auto_encoder2.add(layers.Dropout(drop_out))\n",
    "auto_encoder2.add(layers.Dense(256))\n",
    "auto_encoder2.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder2.add(layers.Reshape(img_shape))\n",
    "auto_encoder2.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder2.summary()\n",
    "\n",
    "history2 = auto_encoder2.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                524320    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 16384)             540672    \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 128, 128)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,066,048\n",
      "Trainable params: 1,066,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None, None).\n",
      "1166/1166 [==============================] - 14s 3ms/step - loss: 0.0603\n",
      "Epoch 2/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0574\n",
      "Epoch 3/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0568\n",
      "Epoch 4/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0565\n",
      "Epoch 5/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0562\n",
      "Epoch 6/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0561\n",
      "Epoch 7/20\n",
      "1166/1166 [==============================] - 4s 3ms/step - loss: 0.0559\n",
      "Epoch 8/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0558\n",
      "Epoch 9/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0557\n",
      "Epoch 10/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0556\n",
      "Epoch 11/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0556\n",
      "Epoch 12/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0555\n",
      "Epoch 13/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0555\n",
      "Epoch 14/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0555\n",
      "Epoch 15/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0555\n",
      "Epoch 16/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0554\n",
      "Epoch 17/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0554\n",
      "Epoch 18/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0554\n",
      "Epoch 19/20\n",
      "1166/1166 [==============================] - 3s 3ms/step - loss: 0.0554\n",
      "Epoch 20/20\n",
      "1166/1166 [==============================] - 3s 2ms/step - loss: 0.0554\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.1\n",
    "\n",
    "img_shape=(s_clean_specs.shape[1],s_clean_specs.shape[2])\n",
    "\n",
    "auto_encoder3=models.Sequential()\n",
    "auto_encoder3.add(layers.Input(shape=img_shape))\n",
    "auto_encoder3.add(layers.Flatten())\n",
    "auto_encoder3.add(layers.Dense(32))\n",
    "auto_encoder3.add(layers.Dropout(drop_out))\n",
    "auto_encoder3.add(layers.Dense(32))\n",
    "auto_encoder3.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "auto_encoder3.add(layers.Reshape(img_shape))\n",
    "auto_encoder3.compile(optimizer='adamax', loss='mse')\n",
    "auto_encoder3.summary()\n",
    "\n",
    "history3 = auto_encoder3.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    batch_size=32\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape_cnn=(s_clean_specs.shape[1],s_clean_specs.shape[2],1)\n",
    "img_shape_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89856"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod((128, 702))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37297, 128, 128, 1), (37297, 128, 128, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_clean_specs.shape,s_noisy_specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37297, 128, 128, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_noisy_specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 32, 32, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 64, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 32)        18464     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 128, 128, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 128, 128, 1)       289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,801\n",
      "Trainable params: 332,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1166/1166 [==============================] - 36s 15ms/step - loss: 0.0237\n",
      "Epoch 2/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0113\n",
      "Epoch 3/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0090\n",
      "Epoch 4/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0078\n",
      "Epoch 5/20\n",
      "1166/1166 [==============================] - 13s 12ms/step - loss: 0.0072\n",
      "Epoch 6/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0067\n",
      "Epoch 7/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0065\n",
      "Epoch 8/20\n",
      "1166/1166 [==============================] - 13s 11ms/step - loss: 0.0060\n",
      "Epoch 9/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0057\n",
      "Epoch 10/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0056\n",
      "Epoch 11/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0053\n",
      "Epoch 12/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0053\n",
      "Epoch 13/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0052\n",
      "Epoch 14/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0050\n",
      "Epoch 15/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0049\n",
      "Epoch 16/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0048\n",
      "Epoch 17/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0048\n",
      "Epoch 18/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0048\n",
      "Epoch 19/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0046\n",
      "Epoch 20/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "img_shape_cnn=(s_noisy_specs.shape[1],s_noisy_specs.shape[2],s_noisy_specs.shape[3])\n",
    "\n",
    "cnn_auto_encoder0=models.Sequential()\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu', input_shape = img_shape_cnn))\n",
    "cnn_auto_encoder0.add(layers.MaxPooling2D(2,strides=2))\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder0.add(layers.MaxPooling2D(2,strides=2))\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder0.add(layers.MaxPooling2D(2,strides=2))\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder0.add(layers.UpSampling2D(2))\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder0.add(layers.UpSampling2D(2))\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder0.add(layers.UpSampling2D(2))\n",
    "cnn_auto_encoder0.add(layers.Conv2D(filters = 1, kernel_size = (3,3), padding = 'Same',\n",
    "                activation ='relu'))\n",
    "#cnn_auto_encoder0.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #cnn_auto_encoder0.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "# cnn_auto_encoder0.add(layers.BatchNormalization())\n",
    "# cnn_auto_encoder0.add(layers.Dropout(drop_out))\n",
    "# cnn_auto_encoder0.add(layers.Flatten())\n",
    "# cnn_auto_encoder0.add(layers.Dense(512, activation = \"relu\"))\n",
    "# cnn_auto_encoder0.add(layers.Dropout(drop_out))\n",
    "# cnn_auto_encoder0.add(layers.Dense(64, activation = \"softmax\"))\n",
    "# cnn_auto_encoder0.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "# cnn_auto_encoder0.add(layers.Reshape(img_shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cnn_auto_encoder0.compile(optimizer='adam', loss='mse')\n",
    "cnn_auto_encoder0.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history_cnn0 = cnn_auto_encoder0.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    batch_size=32\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 5s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_cnn0=cnn_auto_encoder0.predict(s_noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.0227897 ],\n",
       "        [2.9176667 ],\n",
       "        [3.0597537 ],\n",
       "        ...,\n",
       "        [6.6908145 ],\n",
       "        [5.706136  ],\n",
       "        [3.8917763 ]],\n",
       "\n",
       "       [[2.6861646 ],\n",
       "        [2.6189604 ],\n",
       "        [2.8840673 ],\n",
       "        ...,\n",
       "        [4.7674985 ],\n",
       "        [4.137945  ],\n",
       "        [4.9098125 ]],\n",
       "\n",
       "       [[2.2454064 ],\n",
       "        [3.7180912 ],\n",
       "        [3.764681  ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.37897155],\n",
       "        [2.6594043 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.2313939 ],\n",
       "        [1.9505287 ],\n",
       "        [1.3169881 ],\n",
       "        ...,\n",
       "        [0.6854678 ],\n",
       "        [0.22386508],\n",
       "        [0.27422246]],\n",
       "\n",
       "       [[1.9386911 ],\n",
       "        [2.1741734 ],\n",
       "        [2.3559606 ],\n",
       "        ...,\n",
       "        [0.70895904],\n",
       "        [1.0993992 ],\n",
       "        [1.3418329 ]],\n",
       "\n",
       "       [[1.027333  ],\n",
       "        [1.187958  ],\n",
       "        [1.1102605 ],\n",
       "        ...,\n",
       "        [0.9725395 ],\n",
       "        [0.26324183],\n",
       "        [0.20087756]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cnn0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.6116675e-03],\n",
       "        [4.2330422e-02],\n",
       "        [2.9994888e+00],\n",
       "        ...,\n",
       "        [1.0766939e+01],\n",
       "        [1.0084717e+01],\n",
       "        [8.7430801e+00]],\n",
       "\n",
       "       [[2.0240490e+00],\n",
       "        [1.5824387e+00],\n",
       "        [2.2952890e+00],\n",
       "        ...,\n",
       "        [4.0004206e+00],\n",
       "        [4.6528821e+00],\n",
       "        [3.4321313e+00]],\n",
       "\n",
       "       [[3.6204121e+00],\n",
       "        [3.9337368e+00],\n",
       "        [4.4218721e+00],\n",
       "        ...,\n",
       "        [2.2771921e+00],\n",
       "        [1.7581837e+00],\n",
       "        [2.3866873e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.5758204e+00],\n",
       "        [2.7024705e+00],\n",
       "        [2.0233986e+00],\n",
       "        ...,\n",
       "        [1.5009434e-03],\n",
       "        [1.5728220e-02],\n",
       "        [1.0320277e+00]],\n",
       "\n",
       "       [[1.9026399e+00],\n",
       "        [1.8726494e+00],\n",
       "        [1.3823597e+00],\n",
       "        ...,\n",
       "        [1.3814447e+00],\n",
       "        [1.6964116e+00],\n",
       "        [1.9088768e+00]],\n",
       "\n",
       "       [[1.1812829e+00],\n",
       "        [1.3547335e+00],\n",
       "        [1.5787264e+00],\n",
       "        ...,\n",
       "        [7.7776515e-01],\n",
       "        [8.7209022e-01],\n",
       "        [5.3810471e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_noisy_specs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't extend empty axis 1 using modes other than 'constant' or 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49minverse\u001b[39m.\u001b[39;49mmel_to_audio(preds_cnn0[\u001b[39m0\u001b[39;49m], \n\u001b[0;32m      2\u001b[0m                                         sr\u001b[39m=\u001b[39;49m\u001b[39m22050\u001b[39;49m, \n\u001b[0;32m      3\u001b[0m                                          n_fft\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m, \n\u001b[0;32m      4\u001b[0m                                          hop_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, \n\u001b[0;32m      5\u001b[0m                                         win_length\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \n\u001b[0;32m      6\u001b[0m                                          window\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhann\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      7\u001b[0m                                         center\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m      8\u001b[0m                                          pad_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreflect\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      9\u001b[0m                                         power\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, \n\u001b[0;32m     10\u001b[0m                                         n_iter\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\feature\\inverse.py:198\u001b[0m, in \u001b[0;36mmel_to_audio\u001b[1;34m(M, sr, n_fft, hop_length, win_length, window, center, pad_mode, power, n_iter, length, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m\"\"\"Invert a mel power spectrogram to audio using Griffin-Lim.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[39mThis is primarily a convenience wrapper for:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39mlibrosa.feature.inverse.mel_to_stft\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m stft \u001b[39m=\u001b[39m mel_to_stft(M, sr\u001b[39m=\u001b[39msr, n_fft\u001b[39m=\u001b[39mn_fft, power\u001b[39m=\u001b[39mpower, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 198\u001b[0m \u001b[39mreturn\u001b[39;00m griffinlim(\n\u001b[0;32m    199\u001b[0m     stft,\n\u001b[0;32m    200\u001b[0m     n_iter\u001b[39m=\u001b[39;49mn_iter,\n\u001b[0;32m    201\u001b[0m     hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m    202\u001b[0m     win_length\u001b[39m=\u001b[39;49mwin_length,\n\u001b[0;32m    203\u001b[0m     n_fft\u001b[39m=\u001b[39;49mn_fft,\n\u001b[0;32m    204\u001b[0m     window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m    205\u001b[0m     center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m    206\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    207\u001b[0m     length\u001b[39m=\u001b[39;49mlength,\n\u001b[0;32m    208\u001b[0m     pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m    209\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\core\\spectrum.py:2721\u001b[0m, in \u001b[0;36mgriffinlim\u001b[1;34m(S, n_iter, hop_length, win_length, n_fft, window, center, dtype, length, pad_mode, momentum, init, random_state)\u001b[0m\n\u001b[0;32m   2708\u001b[0m inverse \u001b[39m=\u001b[39m istft(\n\u001b[0;32m   2709\u001b[0m     angles,\n\u001b[0;32m   2710\u001b[0m     hop_length\u001b[39m=\u001b[39mhop_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2717\u001b[0m     out\u001b[39m=\u001b[39minverse,\n\u001b[0;32m   2718\u001b[0m )\n\u001b[0;32m   2720\u001b[0m \u001b[39m# Rebuild the spectrogram\u001b[39;00m\n\u001b[1;32m-> 2721\u001b[0m rebuilt \u001b[39m=\u001b[39m stft(\n\u001b[0;32m   2722\u001b[0m     inverse,\n\u001b[0;32m   2723\u001b[0m     n_fft\u001b[39m=\u001b[39;49mn_fft,\n\u001b[0;32m   2724\u001b[0m     hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m   2725\u001b[0m     win_length\u001b[39m=\u001b[39;49mwin_length,\n\u001b[0;32m   2726\u001b[0m     window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m   2727\u001b[0m     center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m   2728\u001b[0m     pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m   2729\u001b[0m     out\u001b[39m=\u001b[39;49mrebuilt,\n\u001b[0;32m   2730\u001b[0m )\n\u001b[0;32m   2732\u001b[0m \u001b[39m# Update our phase estimates\u001b[39;00m\n\u001b[0;32m   2733\u001b[0m angles[:] \u001b[39m=\u001b[39m rebuilt\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\core\\spectrum.py:274\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[0;32m    272\u001b[0m     extra \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    273\u001b[0m     padding[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m (n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m--> 274\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mpad(y, padding, mode\u001b[39m=\u001b[39;49mpad_mode)\n\u001b[0;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m     \u001b[39m# If tail and head do not overlap, then we can implement padding on each part separately\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[39m# and avoid a full copy-pad\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[0;32m    279\u001b[0m     \u001b[39m# \"Middle\" of the signal starts here, and does not depend on head padding\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     start \u001b[39m=\u001b[39m start_k \u001b[39m*\u001b[39m hop_length \u001b[39m-\u001b[39m n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\numpy\\lib\\arraypad.py:814\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m axis, width_pair \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(axes, pad_width):\n\u001b[0;32m    813\u001b[0m         \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mshape[axis] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(width_pair):\n\u001b[1;32m--> 814\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    815\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt extend empty axis \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m using modes other than \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mempty\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(axis)\n\u001b[0;32m    817\u001b[0m             )\n\u001b[0;32m    818\u001b[0m     \u001b[39m# passed, don't need to do anything more as _pad_simple already\u001b[39;00m\n\u001b[0;32m    819\u001b[0m     \u001b[39m# returned the correct result\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39medge\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: can't extend empty axis 1 using modes other than 'constant' or 'empty'"
     ]
    }
   ],
   "source": [
    "res = librosa.feature.inverse.mel_to_audio(preds_cnn0[0], \n",
    "                                        sr=22050, \n",
    "                                         n_fft=2048, \n",
    "                                         hop_length=512, \n",
    "                                        win_length=None, \n",
    "                                         window='hann', \n",
    "                                        center=True, \n",
    "                                         pad_mode='reflect', \n",
    "                                        power=1.0, \n",
    "                                        n_iter=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can't extend empty axis 1 using modes other than 'constant' or 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reverse_spectrogram(preds_cnn0[\u001b[39m0\u001b[39;49m],clean_s_rates[\u001b[39m0\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mtest_cnn0.wav\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m, in \u001b[0;36mreverse_spectrogram\u001b[1;34m(log_spec, sample_rate, output_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreverse_spectrogram\u001b[39m(log_spec,sample_rate, output_path):\n\u001b[0;32m     18\u001b[0m     \u001b[39m#reversed_log=librosa.db_to_power(log_spec)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[39m# step3 converting mel-spectrogrma back to wav file\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     res \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49minverse\u001b[39m.\u001b[39;49mmel_to_audio(log_spec, \n\u001b[0;32m     21\u001b[0m                                         sr\u001b[39m=\u001b[39;49msample_rate, \n\u001b[0;32m     22\u001b[0m                                         n_fft\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m, \n\u001b[0;32m     23\u001b[0m                                         hop_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, \n\u001b[0;32m     24\u001b[0m                                         win_length\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \n\u001b[0;32m     25\u001b[0m                                         window\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhann\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     26\u001b[0m                                         center\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m     27\u001b[0m                                         pad_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreflect\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     28\u001b[0m                                         power\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, \n\u001b[0;32m     29\u001b[0m                                         n_iter\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[0;32m     31\u001b[0m     \u001b[39m# step4 - save it as a wav file\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msoundfile\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\feature\\inverse.py:198\u001b[0m, in \u001b[0;36mmel_to_audio\u001b[1;34m(M, sr, n_fft, hop_length, win_length, window, center, pad_mode, power, n_iter, length, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m\"\"\"Invert a mel power spectrogram to audio using Griffin-Lim.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[39mThis is primarily a convenience wrapper for:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39mlibrosa.feature.inverse.mel_to_stft\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m stft \u001b[39m=\u001b[39m mel_to_stft(M, sr\u001b[39m=\u001b[39msr, n_fft\u001b[39m=\u001b[39mn_fft, power\u001b[39m=\u001b[39mpower, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 198\u001b[0m \u001b[39mreturn\u001b[39;00m griffinlim(\n\u001b[0;32m    199\u001b[0m     stft,\n\u001b[0;32m    200\u001b[0m     n_iter\u001b[39m=\u001b[39;49mn_iter,\n\u001b[0;32m    201\u001b[0m     hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m    202\u001b[0m     win_length\u001b[39m=\u001b[39;49mwin_length,\n\u001b[0;32m    203\u001b[0m     n_fft\u001b[39m=\u001b[39;49mn_fft,\n\u001b[0;32m    204\u001b[0m     window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m    205\u001b[0m     center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m    206\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    207\u001b[0m     length\u001b[39m=\u001b[39;49mlength,\n\u001b[0;32m    208\u001b[0m     pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m    209\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\core\\spectrum.py:2721\u001b[0m, in \u001b[0;36mgriffinlim\u001b[1;34m(S, n_iter, hop_length, win_length, n_fft, window, center, dtype, length, pad_mode, momentum, init, random_state)\u001b[0m\n\u001b[0;32m   2708\u001b[0m inverse \u001b[39m=\u001b[39m istft(\n\u001b[0;32m   2709\u001b[0m     angles,\n\u001b[0;32m   2710\u001b[0m     hop_length\u001b[39m=\u001b[39mhop_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2717\u001b[0m     out\u001b[39m=\u001b[39minverse,\n\u001b[0;32m   2718\u001b[0m )\n\u001b[0;32m   2720\u001b[0m \u001b[39m# Rebuild the spectrogram\u001b[39;00m\n\u001b[1;32m-> 2721\u001b[0m rebuilt \u001b[39m=\u001b[39m stft(\n\u001b[0;32m   2722\u001b[0m     inverse,\n\u001b[0;32m   2723\u001b[0m     n_fft\u001b[39m=\u001b[39;49mn_fft,\n\u001b[0;32m   2724\u001b[0m     hop_length\u001b[39m=\u001b[39;49mhop_length,\n\u001b[0;32m   2725\u001b[0m     win_length\u001b[39m=\u001b[39;49mwin_length,\n\u001b[0;32m   2726\u001b[0m     window\u001b[39m=\u001b[39;49mwindow,\n\u001b[0;32m   2727\u001b[0m     center\u001b[39m=\u001b[39;49mcenter,\n\u001b[0;32m   2728\u001b[0m     pad_mode\u001b[39m=\u001b[39;49mpad_mode,\n\u001b[0;32m   2729\u001b[0m     out\u001b[39m=\u001b[39;49mrebuilt,\n\u001b[0;32m   2730\u001b[0m )\n\u001b[0;32m   2732\u001b[0m \u001b[39m# Update our phase estimates\u001b[39;00m\n\u001b[0;32m   2733\u001b[0m angles[:] \u001b[39m=\u001b[39m rebuilt\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\librosa\\core\\spectrum.py:274\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[0;32m    272\u001b[0m     extra \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    273\u001b[0m     padding[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m (n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m--> 274\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mpad(y, padding, mode\u001b[39m=\u001b[39;49mpad_mode)\n\u001b[0;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m     \u001b[39m# If tail and head do not overlap, then we can implement padding on each part separately\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[39m# and avoid a full copy-pad\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[0;32m    279\u001b[0m     \u001b[39m# \"Middle\" of the signal starts here, and does not depend on head padding\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     start \u001b[39m=\u001b[39m start_k \u001b[39m*\u001b[39m hop_length \u001b[39m-\u001b[39m n_fft \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\audio_dl\\lib\\site-packages\\numpy\\lib\\arraypad.py:814\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m axis, width_pair \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(axes, pad_width):\n\u001b[0;32m    813\u001b[0m         \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mshape[axis] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(width_pair):\n\u001b[1;32m--> 814\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    815\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt extend empty axis \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m using modes other than \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mempty\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(axis)\n\u001b[0;32m    817\u001b[0m             )\n\u001b[0;32m    818\u001b[0m     \u001b[39m# passed, don't need to do anything more as _pad_simple already\u001b[39;00m\n\u001b[0;32m    819\u001b[0m     \u001b[39m# returned the correct result\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39medge\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: can't extend empty axis 1 using modes other than 'constant' or 'empty'"
     ]
    }
   ],
   "source": [
    "reverse_spectrogram(preds_cnn0[0],clean_s_rates[0],'test_cnn0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_111 (Conv2D)         (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 16, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " up_sampling2d_45 (UpSamplin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 32, 32, 64)        73792     \n",
      "                                                                 \n",
      " up_sampling2d_46 (UpSamplin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 64, 64, 32)        18464     \n",
      "                                                                 \n",
      " up_sampling2d_47 (UpSamplin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 128, 128, 1)       289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333,313\n",
      "Trainable params: 333,057\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1166/1166 [==============================] - 15s 12ms/step - loss: 3508.0417\n",
      "Epoch 2/20\n",
      "1166/1166 [==============================] - 16s 13ms/step - loss: 3507.9565\n",
      "Epoch 3/20\n",
      "1166/1166 [==============================] - 15s 12ms/step - loss: 3507.9575\n",
      "Epoch 4/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9568\n",
      "Epoch 5/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9565\n",
      "Epoch 6/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9553\n",
      "Epoch 7/20\n",
      "1166/1166 [==============================] - 14s 12ms/step - loss: 3507.9580\n",
      "Epoch 8/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9558\n",
      "Epoch 9/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9561\n",
      "Epoch 10/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9558\n",
      "Epoch 11/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9563\n",
      "Epoch 12/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9570\n",
      "Epoch 13/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9558\n",
      "Epoch 14/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9575\n",
      "Epoch 15/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9565\n",
      "Epoch 16/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9563\n",
      "Epoch 17/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9568\n",
      "Epoch 18/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9563\n",
      "Epoch 19/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9551\n",
      "Epoch 20/20\n",
      "1166/1166 [==============================] - 15s 13ms/step - loss: 3507.9580\n"
     ]
    }
   ],
   "source": [
    "drop_out=0.5\n",
    "\n",
    "cnn_auto_encoder1=models.Sequential()\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu', input_shape = img_shape_cnn))\n",
    "cnn_auto_encoder1.add(layers.MaxPooling2D(2,strides=2))\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder1.add(layers.MaxPooling2D(2,strides=2))\n",
    "cnn_auto_encoder1.add(layers.BatchNormalization())\n",
    "cnn_auto_encoder0.add(layers.Dropout(drop_out))\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder1.add(layers.MaxPooling2D(2,strides=2))\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder1.add(layers.UpSampling2D(2))\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder1.add(layers.UpSampling2D(2))\n",
    "cnn_auto_encoder1.add(layers.BatchNormalization())\n",
    "cnn_auto_encoder0.add(layers.Dropout(drop_out))\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder1.add(layers.UpSampling2D(2))\n",
    "cnn_auto_encoder1.add(layers.Conv2D(filters = 1, kernel_size = (3,3), padding = 'Same',\n",
    "                activation ='relu'))\n",
    "cnn_auto_encoder1.compile(optimizer='adamax', loss='mse')\n",
    "cnn_auto_encoder1.summary()\n",
    "\n",
    "\n",
    "\n",
    "history_cnn1 = cnn_auto_encoder1.fit(train_gen,\n",
    "                    epochs=20,\n",
    "                    batch_size=8\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "preds=auto_encoder.predict(s_noisy_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 128, 702)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 702)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.88221908e-04, 2.46463984e-04, 2.61851761e-04, ...,\n",
       "        2.57317000e-03, 8.99837411e-04, 2.44650152e-03],\n",
       "       [1.21181156e-03, 9.17276135e-04, 9.90588916e-04, ...,\n",
       "        5.54336328e-03, 2.85331719e-02, 2.60114968e-01],\n",
       "       [1.14793324e+00, 1.52739763e+00, 1.82428646e+00, ...,\n",
       "        2.50480145e-01, 8.19973946e-02, 4.72248858e-03],\n",
       "       ...,\n",
       "       [9.29996677e-05, 9.84362341e-05, 1.06841406e-04, ...,\n",
       "        2.54283252e-04, 6.28159833e-05, 1.36140082e-03],\n",
       "       [2.84687756e-03, 9.32404399e-03, 1.19536798e-02, ...,\n",
       "        1.18909981e-02, 1.26775932e-02, 8.28386191e-03],\n",
       "       [6.48943149e-03, 3.44618829e-03, 1.06449577e-03, ...,\n",
       "        2.61219740e-02, 3.30388226e-04, 1.67555991e-04]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_specs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_log=librosa.db_to_power(preds[0])\n",
    "# step3 converting mel-spectrogrma back to wav file\n",
    "res = librosa.feature.inverse.mel_to_audio(reversed_log, \n",
    "                                           sr=noisy_s_rates[0], \n",
    "                                           n_fft=2048, \n",
    "                                           hop_length=512, \n",
    "                                           win_length=None, \n",
    "                                           window='hann', \n",
    "                                           center=True, \n",
    "                                           pad_mode='reflect', \n",
    "                                           power=2.0, \n",
    "                                           n_iter=32)\n",
    "\n",
    "import soundfile as sf\n",
    "sf.write(\"test2.wav\", res, noisy_s_rates[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertidor de espectrograma a audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('scale.wav', scale, sr, format='ogg', subtype='vorbis')\n",
    "sf.write('audio.wav', audio, sr, format='ogg', subtype='vorbis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
